{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PFA-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor, zeros, zeros_like, cat, eye, mean, sum as tsum, arange, cuda, load\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DistributedSampler, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age2group(age, age_group):\n",
    "    if isinstance(age, np.ndarray):\n",
    "        groups = np.zeros_like(age)\n",
    "    else:\n",
    "        groups = zeros_like(age).to(age.device)\n",
    "\n",
    "    if age_group == 4:\n",
    "        section = [30, 40, 50]\n",
    "    elif age_group == 5:\n",
    "        section = [20, 30, 40, 50]\n",
    "    elif age_group == 7:\n",
    "        section = [10, 20, 30, 40, 50, 60]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    for i, thresh in enumerate(section, 1):\n",
    "        groups[age > thresh] = i\n",
    "        \n",
    "    return groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CACD_Dataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root_dir='materials',\n",
    "            dataset_name='cacd',\n",
    "            age_group=4,\n",
    "            train=False,\n",
    "            source=0,\n",
    "            max_iter=200000,\n",
    "            batch_size=64,\n",
    "            transforms=None\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.dataset_name = dataset_name\n",
    "        self.age_group = age_group\n",
    "        self.train = train\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.total_pairs = batch_size * max_iter\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self._load_meta_data()\n",
    "\n",
    "        self.mean_ages = np.array(\n",
    "            [np.mean(self.ages[self.age_groups == i])\n",
    "            for i in range(self.age_group)]\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        self.label_group_images = []\n",
    "        self.label_group_ages = []\n",
    "\n",
    "        for i in range(self.age_group):\n",
    "            self.label_group_images.append(\n",
    "                self.image_names[self.age_groups == i].tolist())\n",
    "            self.label_group_ages.append(\n",
    "                self.ages[self.age_groups == i].astype(np.float32).tolist())\n",
    "\n",
    "        self.target_labels = np.random.randint(source + 1, self.age_group, self.total_pairs)\n",
    "\n",
    "        pairs = np.array(list(itertools.combinations(range(age_group), 2)))\n",
    "        p = [1, 1, 1, 0.5, 0.5, 0.5]\n",
    "        p = np.array(p) / np.sum(p)\n",
    "        pairs = pairs[np.random.choice(range(len(pairs)), self.total_pairs, p=p), :]\n",
    "        source_labels, target_labels = pairs[:, 0], pairs[:, 1]\n",
    "        self.source_labels = source_labels\n",
    "        self.target_labels = target_labels\n",
    "\n",
    "        self.true_labels = np.random.randint(0, self.age_group, self.total_pairs)\n",
    "\n",
    "    def _load_meta_data(self):\n",
    "        meta = h5py.File(os.path.join(self.root_dir, f\"{self.dataset_name}.mat\"), 'r')\n",
    "\n",
    "        self.ages = meta['celebrityImageData']['age'][0,:]\n",
    "        self.age_groups = np.asanyarray([age2group(np.asanyarray([age]), self.age_group) for age in self.ages])\n",
    "        self.image_names = np.asanyarray(\n",
    "            [''.join(chr(i[0])\n",
    "                     for i in hdf5_object)\n",
    "                     for hdf5_object in [meta[hdf5_object_reference][:] \n",
    "                     for hdf5_object_references in meta['celebrityImageData']['name']\n",
    "                     for hdf5_object_reference in hdf5_object_references]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.ages) == len(self.image_names) and len(self.image_names) == len(self.age_groups):\n",
    "            return len(self.ages)\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source_label = self.source_labels[idx]\n",
    "        target_label = self.target_labels[idx]\n",
    "        true_label = self.true_labels[idx]\n",
    "\n",
    "        source_img = transforms.ToTensor()(pil_loader(os.path.join(self.root_dir, self.dataset_name, random.choice(self.label_group_images[source_label]))))\n",
    "\n",
    "        index = random.randint(0, len(self.label_group_images[true_label]) - 1)\n",
    "        true_img = transforms.ToTensor()(pil_loader(os.path.join(self.root_dir, self.dataset_name, self.label_group_images[true_label][index])))\n",
    "        true_age = self.label_group_ages[true_label][index]\n",
    "        mean_age = self.mean_ages[target_label]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            source_img = self.transforms(source_img)\n",
    "            true_img = self.transforms(true_img)\n",
    "\n",
    "        return source_img, true_img, source_label, target_label, true_label, true_age, mean_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, *norm_index):\n",
    "        self.loader = iter(loader)\n",
    "        self.normlize = lambda x: x.sub_(0.5).div_(0.5)\n",
    "        self.norm_index = norm_index\n",
    "        #self.stream = cuda.Stream()\n",
    "        self.preload()\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            return\n",
    "        #with cuda.stream(self.stream):\n",
    "        \n",
    "        self.next_input = [\n",
    "            self.normlize(x) if i in self.norm_index and type(x) is torch.tensor else x\n",
    "            for i, x in enumerate(self.next_input)\n",
    "        ]\n",
    "\n",
    "    def next(self):\n",
    "        #cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        self.preload()\n",
    "        return input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFA-GAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, age_group, conv_dim=64, repeat_num=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.age_group = age_group\n",
    "        self.conv_dim = conv_dim\n",
    "        self.repeat_num = repeat_num\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            self.conv_dim,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        nf_mult = 1\n",
    "\n",
    "        # gradually increase the number of filters\n",
    "        for n in range(1, self.repeat_num):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            \n",
    "            layers += [\n",
    "                nn.utils.spectral_norm(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=self.conv_dim * nf_mult_prev + (self.age_group if n == 1 else 0),\n",
    "                        out_channels=self.conv_dim * nf_mult,\n",
    "                        kernel_size=4,\n",
    "                        stride=2,\n",
    "                        padding=1,\n",
    "                        bias=True\n",
    "                    )\n",
    "                ),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "        \n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** self.repeat_num, 8)\n",
    "        \n",
    "        layers += [\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.conv_dim * nf_mult_prev,\n",
    "                out_channels=self.conv_dim * nf_mult,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.conv_dim * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.conv_dim * nf_mult,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.main = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, inputs, condition):\n",
    "        x = F.leaky_relu(self.conv1(inputs), 0.2, inplace=True)\n",
    "        condition = self._group2feature(\n",
    "            condition,\n",
    "            feature_size=x.size(2),\n",
    "            age_group=self.age_group\n",
    "        ).to(x)\n",
    "        return self.main(cat([x, condition], dim=1))\n",
    "\n",
    "    def _group2feature(self, group, age_group, feature_size):\n",
    "        onehot = self._group2onehot(\n",
    "            group, \n",
    "            age_group\n",
    "        )\n",
    "        return onehot.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, feature_size, feature_size)\n",
    "\n",
    "    def _group2onehot(self, groups, age_group):\n",
    "        code = eye(age_group)[groups.squeeze()]\n",
    "        if len(code.size()) > 1:\n",
    "            return code\n",
    "        return code.unsqueeze(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.n_channels = channels\n",
    "        self._init_model()\n",
    "    \n",
    "    def _init_model(self):\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                self.n_channels,\n",
    "                self.n_channels,\n",
    "                3,\n",
    "                1,\n",
    "                1\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                self.n_channels,\n",
    "                self.n_channels,\n",
    "                3,\n",
    "                1,\n",
    "                1\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.n_channels),\n",
    "        ]\n",
    "\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.main(x)\n",
    "        return F.leaky_relu(residual + x, 0.2, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorSubNetwork(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_residual_blocks=4):\n",
    "        super(GeneratorSubNetwork, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.n_residual_blocks = n_residual_blocks\n",
    "\n",
    "        self._init_model()\n",
    "    \n",
    "    def _init_model(self):\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=32,\n",
    "                kernel_size=9,\n",
    "                stride=1,\n",
    "                padding=4\n",
    "            ),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        for _ in range(self.n_residual_blocks):\n",
    "            layers.append(ResidualBlock(128))\n",
    "\n",
    "        layers.extend([\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=3,\n",
    "                kernel_size=9,\n",
    "                stride=1,\n",
    "                padding=4\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "        self.main = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, age_group, n_residual_blocks=4):\n",
    "        super(Generator, self).__init__()\n",
    "        self.age_group = age_group\n",
    "        self._init_model(n_residual_blocks)\n",
    "    \n",
    "    def _init_model(self, n_residual_blocks):\n",
    "        self.sub_networks = nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.age_group - 1):\n",
    "            self.sub_networks.append(GeneratorSubNetwork(\n",
    "                in_channels=3,\n",
    "                n_residual_blocks=n_residual_blocks\n",
    "            ))\n",
    "    \n",
    "    def forward(self, x, source_label: Tensor, target_label: Tensor):\n",
    "        condition = self._pfa_encoding(source_label, target_label, self.age_group)\n",
    "        for i in range(self.age_group - 1):\n",
    "            aging_effects = self.sub_networks[i](x)\n",
    "            x = x + aging_effects * condition[:, i]\n",
    "        return x\n",
    "\n",
    "    def _pfa_encoding(self, source, target, age_group):\n",
    "        source, target = source.long(), target.long()\n",
    "        code = zeros((source.size(0), age_group - 1, 1, 1, 1)).to(source)\n",
    "        for i in range(source.size(0)):\n",
    "            code[i, source[i]: target[i], ...] = 1\n",
    "        return code\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryAgeClassifier(nn.Module):\n",
    "    def __init__(self, conv_dim=64, channels=3, classes=101):\n",
    "        super(AuxiliaryAgeClassifier, self).__init__()\n",
    "\n",
    "        self.conv_dim = conv_dim\n",
    "        self.channels = channels\n",
    "        self.classes = classes\n",
    "\n",
    "        self._init_model()\n",
    "\n",
    "    def _add_vgg_block(self, in_channels, out_channels, more=False):\n",
    "        layers = [\n",
    "            (\n",
    "                'conv1',\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                'relu1',\n",
    "                nn.ReLU(inplace=True)\n",
    "            ),\n",
    "            (\n",
    "                'conv2',\n",
    "                nn.Conv2d(\n",
    "                    out_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                'relu2',\n",
    "                nn.ReLU(inplace=True)\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        if more:\n",
    "            layers.extend([\n",
    "                (\n",
    "                    'conv3',\n",
    "                    nn.Conv2d(\n",
    "                        out_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=3,\n",
    "                        stride=1,\n",
    "                        padding=1\n",
    "                    )\n",
    "                ),\n",
    "                (\n",
    "                    'relu3',\n",
    "                    nn.ReLU(inplace=True)\n",
    "                ),\n",
    "            ])\n",
    "\n",
    "        layers.append(('maxpool', nn.MaxPool2d(kernel_size=2, stride=2)))\n",
    "\n",
    "        return nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.conv = nn.Sequential(\n",
    "            self._add_vgg_block(self.channels, self.conv_dim),\n",
    "            self._add_vgg_block(self.conv_dim, self.conv_dim*2),\n",
    "            self._add_vgg_block(self.conv_dim*2, self.conv_dim*4, True),\n",
    "            self._add_vgg_block(self.conv_dim*4, self.conv_dim*8, True),\n",
    "            self._add_vgg_block(self.conv_dim*8, self.conv_dim*8, True),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.conv_dim*7*7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.cls = nn.Linear(4096, self.classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward operation of the net.\n",
    "        \"\"\"\n",
    "        in_size = x.shape[0]\n",
    "        x = self.conv(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.cls(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFA-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PFA_GAN(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha,\n",
    "            pix_loss_weight,\n",
    "            gan_loss_weight,\n",
    "            id_loss_weight,\n",
    "            age_loss_weight,\n",
    "            age_group=4,\n",
    "            image_size=256,\n",
    "            pretrained_image_size=256,\n",
    "            init_lr=1e-4,\n",
    "            restore_iter=0,\n",
    "            max_iter=200000,\n",
    "            save_iter=2000,\n",
    "            decay_pix_factor=0,\n",
    "            decay_pix_n=2000,\n",
    "            num_workers=0,\n",
    "            batch_size=256):\n",
    "        self.age_group = age_group\n",
    "        self.image_size = image_size\n",
    "        self.pretrained_image_size = pretrained_image_size\n",
    "        self.init_lr = init_lr\n",
    "        self.restore_iter = restore_iter\n",
    "        self.max_iter = max_iter\n",
    "        self.save_iter = save_iter\n",
    "        self.pix_loss_weight = pix_loss_weight\n",
    "        self.decay_pix_factor = decay_pix_factor\n",
    "        self.decay_pix_n = decay_pix_n\n",
    "        self.gan_loss_weight = gan_loss_weight\n",
    "        self.alpha = alpha\n",
    "        self.id_loss_weight = id_loss_weight\n",
    "        self.age_loss_weight = age_loss_weight\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.prefetcher = self._get_train_loader()\n",
    "\n",
    "        self._init_model()\n",
    "    \n",
    "    def fit(self):\n",
    "        for n_iter in range(self.restore_iter + 1, self.max_iter + 1):\n",
    "            inputs = self.prefetcher.next()\n",
    "            self.train(inputs, n_iter=n_iter)\n",
    "            if n_iter % self.save_iter == 0 or n_iter == self.max_iter:\n",
    "                pass\n",
    "\n",
    "    def train(self, inputs, n_iter):\n",
    "        source_img, true_img, source_label, target_label, true_label, true_age, mean_age = inputs\n",
    "        \n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        if self.image_size < self.pretrained_image_size:\n",
    "            source_img_small = F.interpolate(source_img, self.image_size)\n",
    "            true_img_small = F.interpolate(true_img, self.image_size)\n",
    "        else:\n",
    "            source_img_small = source_img\n",
    "            true_img_small = true_img\n",
    "        \n",
    "        g_source = self.generator(source_img_small, source_label, target_label)\n",
    "        \n",
    "        if self.image_size < self.pretrained_image_size:\n",
    "            g_source_pretrained = F.interpolate(g_source, self.pretrained_image_size)\n",
    "        else:\n",
    "            g_source_pretrained = g_source\n",
    "\n",
    "        ###########################\n",
    "        # Train Discriminator\n",
    "        ###########################\n",
    "        self.optimizer_discriminator.zero_grad()\n",
    "        d1_logit = self.discriminator(true_img_small, true_label)\n",
    "        # d2_logit = self.discriminator(true_img, source_label)\n",
    "        d3_logit = self.discriminator(g_source.detach(), target_label)\n",
    "\n",
    "        # d_loss = 0.5 * (ls_gan(d1_logit, 1.) + ls_gan(d2_logit, 0.) + ls_gan(d3_logit, 0.))\n",
    "        d_loss = 0.5 * (self._ls_gan(d1_logit, 1.) + self._ls_gan(d3_logit, 0.))\n",
    "\n",
    "        # COMMENT IN \n",
    "        #with amp.scale_loss(d_loss, self.optimizer_discriminator) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        self.optimizer_discriminator.step()\n",
    "\n",
    "        ###########################\n",
    "        # Train Generator\n",
    "        ###########################\n",
    "        self.optimizer_generator.zero_grad()\n",
    "\n",
    "        ###########################\n",
    "        # GAN Loss\n",
    "        ###########################\n",
    "        gan_logit = self.discriminator(g_source, target_label)\n",
    "        g_loss = self._ls_gan(gan_logit, 1.)\n",
    "\n",
    "        ###########################\n",
    "        # Age Loss\n",
    "        ###########################\n",
    "        age_loss = self._age_criterion(g_source_pretrained, mean_age)\n",
    "\n",
    "        ###########################\n",
    "        # L1 Loss\n",
    "        ###########################\n",
    "        l1_loss = F.l1_loss(g_source_pretrained, source_img)\n",
    "\n",
    "        ###########################\n",
    "        # SSIM loss\n",
    "        ###########################\n",
    "        ssim_loss = self._compute_ssim_loss(g_source_pretrained, source_img, window_size=10)\n",
    "\n",
    "        ###########################\n",
    "        # ID Loss\n",
    "        ###########################\n",
    "        id_loss = F.mse_loss(\n",
    "            self._extract_vgg_face(g_source_pretrained),\n",
    "            self._extract_vgg_face(source_img)\n",
    "        )\n",
    "\n",
    "        pix_loss_weight = max(\n",
    "            self.pix_loss_weight,\n",
    "            self.pix_loss_weight * (self.decay_pix_factor ** (n_iter // self.decay_pix_n))\n",
    "        )\n",
    "\n",
    "        total_loss = \\\n",
    "            g_loss * self.gan_loss_weight + \\\n",
    "            (l1_loss * (1 - self.alpha) + ssim_loss * self.alpha) * pix_loss_weight + \\\n",
    "            id_loss * self.id_loss_weight + \\\n",
    "            age_loss * self.age_loss_weight\n",
    "        \n",
    "        # COMMENT IN \n",
    "        # with amp.scale_loss(total_loss, self.optimizer_generator) as scaled_loss:\n",
    "        #     scaled_loss.backward()\n",
    "        self.optimizer_generator.step()\n",
    "\n",
    "    def _ls_gan(self, inputs, targets):\n",
    "        return mean((inputs - targets) ** 2)\n",
    "    \n",
    "    def _age_criterion(self, input, gt_age):\n",
    "        age_logit, group_logit = self.age_classifier(input)\n",
    "        return F.mse_loss(self._get_dex_age(age_logit), gt_age)# + \\\n",
    "               #F.cross_entropy(group_logit, age2group(gt_age, self.age_group).long())\n",
    "    \n",
    "    def _get_dex_age(self, pred):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        value = tsum(pred * arange(pred.size(1)).to(pred.device), dim=1)\n",
    "        return value\n",
    "    \n",
    "    def _compute_ssim_loss(self, img1, img2, window_size=11):\n",
    "        channel = img1.size(1)\n",
    "        window = self._create_window(window_size, channel).to(img1.device)\n",
    "\n",
    "        mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "        mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "        return 1.0 - ssim_map.mean()\n",
    "\n",
    "    def _create_window(self, window_size, channel):\n",
    "        _1D_window = self._gaussian(window_size, 1.5).unsqueeze(1)\n",
    "        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "        return window\n",
    "    \n",
    "    def _gaussian(self, window_size, sigma):\n",
    "        gauss = Tensor([math.exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "        return gauss / gauss.sum()\n",
    "    \n",
    "    def _extract_vgg_face(self, inputs):\n",
    "        inputs = self._normalize((F.hardtanh(inputs) * 0.5 + 0.5) * 255,\n",
    "                           [129.1863, 104.7624, 93.5940],\n",
    "                           [1.0, 1.0, 1.0])\n",
    "        return self.vgg_face(inputs)\n",
    "    \n",
    "    def _normalize(self, input, mean, std):\n",
    "        mean = Tensor(mean).to(input.device)\n",
    "        std = Tensor(std).to(input.device)\n",
    "        return input.sub(mean[None, :, None, None]).div(std[None, :, None, None])\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.generator = Generator(self.age_group)\n",
    "        self.generator.apply(self._weights_init)\n",
    "\n",
    "        self.discriminator = Discriminator(\n",
    "            age_group=self.age_group,\n",
    "            repeat_num=int(np.log2(self.image_size) - 4),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.vgg_face = torchvision.models.vgg16(num_classes=2622)\n",
    "        self.vgg_face.eval()\n",
    "\n",
    "        self.age_classifier = AuxiliaryAgeClassifier(\n",
    "            age_group=self.age_group\n",
    "        )\n",
    "        self.age_classifier.load_state_dict(\n",
    "            self._load_network(\n",
    "                os.path.join(\n",
    "                    'materials',\n",
    "                    'models',\n",
    "                    'age_sd.pth.obj'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.age_classifier.eval()\n",
    "\n",
    "        self.optimizer_discriminator = Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            self.init_lr,\n",
    "            betas=(0.5, 0.99)\n",
    "        )\n",
    "\n",
    "        self.optimizer_generator = Adam(\n",
    "            self.generator.parameters(),\n",
    "            self.init_lr,\n",
    "            betas=(0.5, 0.99)\n",
    "        )\n",
    "\n",
    "    def _load_network(self, state_dict):\n",
    "        if isinstance(state_dict, str):\n",
    "            state_dict = load(state_dict, map_location='cpu')\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            namekey = k.replace('module.', '')  # remove `module.`\n",
    "            new_state_dict[namekey] = v\n",
    "        return new_state_dict\n",
    "\n",
    "    def _get_train_loader(self):\n",
    "        transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(self.pretrained_image_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        train_dataset = CACD_Dataset(\n",
    "            'materials',\n",
    "            'cacd'\n",
    "        )\n",
    "\n",
    "        #train_sampler = DistributedSampler(\n",
    "        #    train_dataset, shuffle=False\n",
    "        #)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            #sampler=train_sampler\n",
    "        )\n",
    "\n",
    "        return DataPrefetcher(train_loader, [0, 1])\n",
    "\n",
    "    def _weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            # torch.nn.init.kaiming_normal(m.weight.data, mode='fan_in')\n",
    "            # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            if hasattr(m.bias, 'data'):\n",
    "                m.bias.data.fill_(0)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AuxiliaryAgeClassifier.__init__() got an unexpected keyword argument 'age_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pfa_gan \u001b[39m=\u001b[39m PFA_GAN(\n\u001b[1;32m      2\u001b[0m     alpha\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     pix_loss_weight\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     gan_loss_weight\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     id_loss_weight\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     age_loss_weight\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m )\n",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m, in \u001b[0;36mPFA_GAN.__init__\u001b[0;34m(self, alpha, pix_loss_weight, gan_loss_weight, id_loss_weight, age_loss_weight, age_group, image_size, pretrained_image_size, init_lr, restore_iter, max_iter, save_iter, decay_pix_factor, decay_pix_n, num_workers, batch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefetcher \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_train_loader()\n\u001b[0;32m---> 39\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_model()\n",
      "Cell \u001b[0;32mIn[10], line 203\u001b[0m, in \u001b[0;36mPFA_GAN._init_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvgg_face \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mvgg16(num_classes\u001b[39m=\u001b[39m\u001b[39m2622\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvgg_face\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mage_classifier \u001b[39m=\u001b[39m AuxiliaryAgeClassifier(\n\u001b[1;32m    204\u001b[0m     age_group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mage_group\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    206\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mage_classifier\u001b[39m.\u001b[39mload_state_dict(\n\u001b[1;32m    207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_network(\n\u001b[1;32m    208\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     )\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mage_classifier\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: AuxiliaryAgeClassifier.__init__() got an unexpected keyword argument 'age_group'"
     ]
    }
   ],
   "source": [
    "pfa_gan = PFA_GAN(\n",
    "    alpha=1e-4,\n",
    "    pix_loss_weight=1e-4,\n",
    "    gan_loss_weight=1e-4,\n",
    "    id_loss_weight=1e-4,\n",
    "    age_loss_weight=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfa_gan.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-b-ai-seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
