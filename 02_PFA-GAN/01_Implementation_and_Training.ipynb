{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PFA-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor, zeros, zeros_like, cat, eye, mean, cuda\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "from apex import amp\n",
    "from apex.parallel import DistributedDataParallel\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age2group(age, age_group):\n",
    "    if isinstance(age, np.ndarray):\n",
    "        groups = np.zeros_like(age)\n",
    "    else:\n",
    "        groups = zeros_like(age).to(age.device)\n",
    "\n",
    "    if age_group == 4:\n",
    "        section = [30, 40, 50]\n",
    "    elif age_group == 5:\n",
    "        section = [20, 30, 40, 50]\n",
    "    elif age_group == 7:\n",
    "        section = [10, 20, 30, 40, 50, 60]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    for i, thresh in enumerate(section, 1):\n",
    "        groups[age > thresh] = i\n",
    "        \n",
    "    return groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CACD_Dataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root_dir='data',\n",
    "            dataset_name='cacd',\n",
    "            age_group=4,\n",
    "            train=False,\n",
    "            source=0,\n",
    "            max_iter=200000,\n",
    "            batch_size=64,\n",
    "            transforms=None,\n",
    "            n_images=-1\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.dataset_name = dataset_name\n",
    "        self.age_group = age_group\n",
    "        self.train = train\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.total_pairs = batch_size * max_iter\n",
    "        self.transforms = transforms\n",
    "        self.n_images = n_images\n",
    "\n",
    "        self._load_meta_data()\n",
    "\n",
    "        self.mean_ages = np.array(\n",
    "            [np.mean(self.ages[self.age_groups == i])\n",
    "            for i in range(self.age_group)]\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        self.label_group_images = []\n",
    "        self.label_group_ages = []\n",
    "\n",
    "        for i in range(self.age_group):\n",
    "            self.label_group_images.append(\n",
    "                self.image_names[self.age_groups == i].tolist())\n",
    "            self.label_group_ages.append(\n",
    "                self.ages[self.age_groups == i].astype(np.float32).tolist())\n",
    "\n",
    "        self.target_labels = np.random.randint(source + 1, self.age_group, self.total_pairs)\n",
    "\n",
    "        pairs = np.array(list(itertools.combinations(range(age_group), 2)))\n",
    "        p = [1, 1, 1, 0.5, 0.5, 0.5]\n",
    "        p = np.array(p) / np.sum(p)\n",
    "        pairs = pairs[np.random.choice(range(len(pairs)), self.total_pairs, p=p), :]\n",
    "        source_labels, target_labels = pairs[:, 0], pairs[:, 1]\n",
    "        self.source_labels = source_labels\n",
    "        self.target_labels = target_labels\n",
    "\n",
    "        self.true_labels = np.random.randint(0, self.age_group, self.total_pairs)\n",
    "\n",
    "    def _load_meta_data(self):\n",
    "        meta = h5py.File(os.path.join(self.root_dir, f\"{self.dataset_name}.mat\"), 'r')\n",
    "\n",
    "        self.ages = meta['celebrityImageData']['age'][0,:]\n",
    "        self.age_groups = np.asanyarray([age2group(np.asanyarray([age]), self.age_group) for age in self.ages])\n",
    "        self.image_names = np.asanyarray(\n",
    "            [''.join(chr(i[0])\n",
    "                    for i in hdf5_object)\n",
    "                    for hdf5_object in [meta[hdf5_object_reference][:] \n",
    "                    for hdf5_object_references in meta['celebrityImageData']['name']\n",
    "                    for hdf5_object_reference in hdf5_object_references]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.ages) == len(self.image_names) and len(self.image_names) == len(self.age_groups):\n",
    "            return len(self.ages)\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source_label = self.source_labels[idx]\n",
    "        target_label = self.target_labels[idx]\n",
    "        true_label = self.true_labels[idx]\n",
    "\n",
    "        source_img = transforms.ToTensor()(pil_loader(os.path.join(self.root_dir, self.dataset_name, random.choice(self.label_group_images[source_label]))).resize((248,248)))\n",
    "\n",
    "        index = random.randint(0, len(self.label_group_images[true_label]) - 1)\n",
    "        true_img = transforms.ToTensor()(pil_loader(os.path.join(self.root_dir, self.dataset_name, self.label_group_images[true_label][index])).resize((248,248)))\n",
    "        true_age = self.label_group_ages[true_label][index]\n",
    "        mean_age = self.mean_ages[target_label]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            source_img = self.transforms(source_img)\n",
    "            true_img = self.transforms(true_img)\n",
    "\n",
    "        return source_img, true_img, source_label, target_label, true_label, true_age, mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, *norm_index):\n",
    "        self.loader = iter(loader)\n",
    "        self.normlize = lambda x: x.sub_(0.5).div_(0.5)\n",
    "        self.norm_index = norm_index\n",
    "        self.stream = cuda.Stream()\n",
    "        self.preload()\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            return\n",
    "        with cuda.stream(self.stream):\n",
    "            self.next_input = [\n",
    "                self.normlize(x.cuda(non_blocking=True)) if i in self.norm_index else x.cuda(non_blocking=True)\n",
    "                for i, x in enumerate(self.next_input)\n",
    "            ]\n",
    "\n",
    "    def next(self):\n",
    "        cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        self.preload()\n",
    "        return input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFA-GAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, age_group, conv_dim=64, repeat_num=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.age_group = age_group\n",
    "        self.conv_dim = conv_dim\n",
    "        self.repeat_num = repeat_num\n",
    "        \n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            self.conv_dim,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        nf_mult = 1\n",
    "\n",
    "        # gradually increase the number of filters\n",
    "        for n in range(1, self.repeat_num):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            \n",
    "            layers += [\n",
    "                nn.utils.spectral_norm(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=self.conv_dim * nf_mult_prev + (self.age_group if n == 1 else 0),\n",
    "                        out_channels=self.conv_dim * nf_mult,\n",
    "                        kernel_size=4,\n",
    "                        stride=2,\n",
    "                        padding=1,\n",
    "                        bias=True\n",
    "                    )\n",
    "                ),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "        \n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** self.repeat_num, 8)\n",
    "        \n",
    "        layers += [\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.conv_dim * nf_mult_prev,\n",
    "                out_channels=self.conv_dim * nf_mult,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.conv_dim * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.conv_dim * nf_mult,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.main = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, inputs, condition):\n",
    "        x = F.leaky_relu(self.conv1(inputs), 0.2, inplace=True)\n",
    "        condition = self._group2feature(\n",
    "            condition.to(device),\n",
    "            feature_size=x.size(2),\n",
    "            age_group=self.age_group\n",
    "        ).to(x)\n",
    "        return self.main(cat([x, condition], dim=1))\n",
    "\n",
    "    def _group2feature(self, group, age_group, feature_size):\n",
    "        onehot = self._group2onehot(\n",
    "            group, \n",
    "            age_group\n",
    "        )\n",
    "        return onehot.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, feature_size, feature_size).to(device)\n",
    "\n",
    "    def _group2onehot(self, groups, age_group):\n",
    "        code = eye(age_group).to(device)[groups.squeeze()]\n",
    "        if len(code.size()) > 1:\n",
    "            return code\n",
    "        return code.unsqueeze(0).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.n_channels = channels\n",
    "        self._init_model()\n",
    "    \n",
    "    def _init_model(self):\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                self.n_channels,\n",
    "                self.n_channels,\n",
    "                3,\n",
    "                1,\n",
    "                1\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                self.n_channels,\n",
    "                self.n_channels,\n",
    "                3,\n",
    "                1,\n",
    "                1\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.n_channels),\n",
    "        ]\n",
    "\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.main(x)\n",
    "        return F.leaky_relu(residual + x, 0.2, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorSubNetwork(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_residual_blocks=4):\n",
    "        super(GeneratorSubNetwork, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.n_residual_blocks = n_residual_blocks\n",
    "\n",
    "        self._init_model()\n",
    "    \n",
    "    def _init_model(self):\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=32,\n",
    "                kernel_size=9,\n",
    "                stride=1,\n",
    "                padding=4\n",
    "            ),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        for _ in range(self.n_residual_blocks):\n",
    "            layers.append(ResidualBlock(128))\n",
    "\n",
    "        layers.extend([\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=3,\n",
    "                kernel_size=9,\n",
    "                stride=1,\n",
    "                padding=4\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "        self.main = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, age_group, n_residual_blocks=4):\n",
    "        super(Generator, self).__init__()\n",
    "        self.age_group = age_group\n",
    "        self._init_model(n_residual_blocks)\n",
    "    \n",
    "    def _init_model(self, n_residual_blocks):\n",
    "        self.sub_networks = nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.age_group - 1):\n",
    "            self.sub_networks.append(GeneratorSubNetwork(\n",
    "                in_channels=3,\n",
    "                n_residual_blocks=n_residual_blocks\n",
    "            ))\n",
    "    \n",
    "    def forward(self, x, source_label: Tensor, target_label: Tensor):\n",
    "        condition = self._pfa_encoding(source_label, target_label, self.age_group).to(device)\n",
    "        for i in range(self.age_group - 1):\n",
    "            aging_effects = self.sub_networks[i](x)\n",
    "            x = x + aging_effects * condition[:, i]\n",
    "        return x\n",
    "\n",
    "    def _pfa_encoding(self, source, target, age_group):\n",
    "        source, target = source.long(), target.long()\n",
    "        code = zeros((source.size(0), age_group - 1, 1, 1, 1)).to(source)\n",
    "        for i in range(source.size(0)):\n",
    "            code[i, source[i]: target[i], ...] = 1\n",
    "        return code\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryAgeClassifier(nn.Module):\n",
    "    def __init__(self, pool='max'):\n",
    "        super(AuxiliaryAgeClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.fc6 = nn.Linear(25088, 4096, bias=True)\n",
    "        self.fc7 = nn.Linear(4096, 4096, bias=True)\n",
    "        self.fc8_101 = nn.Linear(4096, 101, bias=True)\n",
    "        \n",
    "        if pool == 'max':\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif pool == 'avg':\n",
    "            self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        out['r11'] = F.relu(self.conv1_1(x))\n",
    "        out['r12'] = F.relu(self.conv1_2(out['r11']))\n",
    "        out['p1'] = self.pool1(out['r12'])\n",
    "        out['r21'] = F.relu(self.conv2_1(out['p1']))\n",
    "        out['r22'] = F.relu(self.conv2_2(out['r21']))\n",
    "        out['p2'] = self.pool2(out['r22'])\n",
    "        out['r31'] = F.relu(self.conv3_1(out['p2']))\n",
    "        out['r32'] = F.relu(self.conv3_2(out['r31']))\n",
    "        out['r33'] = F.relu(self.conv3_3(out['r32']))\n",
    "        out['p3'] = self.pool3(out['r33'])\n",
    "        out['r41'] = F.relu(self.conv4_1(out['p3']))\n",
    "        out['r42'] = F.relu(self.conv4_2(out['r41']))\n",
    "        out['r43'] = F.relu(self.conv4_3(out['r42']))\n",
    "        out['p4'] = self.pool4(out['r43'])\n",
    "        out['r51'] = F.relu(self.conv5_1(out['p4']))\n",
    "        out['r52'] = F.relu(self.conv5_2(out['r51']))\n",
    "        out['r53'] = F.relu(self.conv5_3(out['r52']))\n",
    "        out['p5'] = self.pool5(out['r53'])\n",
    "        out['p5'] = out['p5'].view(out['p5'].size(0), -1)\n",
    "        out['fc6'] = F.relu(self.fc6(out['p5']))\n",
    "        out['fc7'] = F.relu(self.fc7(out['fc6']))\n",
    "        out['fc8'] = self.fc8_101(out['fc7'])\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFA-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PFA_GAN(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha_fea,\n",
    "            alpha_ssim,\n",
    "            pix_loss_weight,\n",
    "            gan_loss_weight,\n",
    "            id_loss_weight,\n",
    "            age_loss_weight,\n",
    "            age_group=4,\n",
    "            init_lr=1e-4,\n",
    "            decay_pix_factor=0.,\n",
    "            decay_pix_n=2000,\n",
    "            batch_size=64,\n",
    "            image_size=256,\n",
    "            print_log=50,\n",
    "            save_iter=10,\n",
    "            restore_iter=0,\n",
    "            max_iter=200000,\n",
    "            num_workers=0,\n",
    "            experiment=0):\n",
    "        \n",
    "        self.age_group = age_group\n",
    "        self.image_size = image_size\n",
    "        self.init_lr = init_lr\n",
    "        self.print_log = print_log\n",
    "        self.save_iter = save_iter\n",
    "        self.restore_iter = restore_iter\n",
    "        self.max_iter = max_iter\n",
    "        self.pix_loss_weight = pix_loss_weight\n",
    "        self.decay_pix_factor = decay_pix_factor\n",
    "        self.decay_pix_n = decay_pix_n\n",
    "        self.gan_loss_weight = gan_loss_weight\n",
    "        self.alpha_fea = alpha_fea\n",
    "        self.alpha_ssim = alpha_ssim\n",
    "        self.id_loss_weight = id_loss_weight\n",
    "        self.age_loss_weight = age_loss_weight\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.experiment = experiment\n",
    "\n",
    "        self.test_images = self._get_test_images()\n",
    "        self.prefetcher = self._get_train_loader()\n",
    "\n",
    "        self._init_model()\n",
    "\n",
    "        self.generator_losses = []\n",
    "        self.discriminator_losses = []\n",
    "        self.age_losses = []\n",
    "        self.l1_losses = []\n",
    "        self.ssim_losses = []\n",
    "        self.id_losses = []\n",
    "        self.total_losses = []\n",
    "    \n",
    "    def fit(self):\n",
    "        for n_iter in range(self.restore_iter + 1, self.max_iter + 1):\n",
    "            inputs = self.prefetcher.next()\n",
    "\n",
    "            d1_logit, d3_logit, g_loss, d_loss, gan_logit, age_loss, l1_loss, ssim_loss, id_loss, total_loss = self.train(inputs, n_iter=n_iter)\n",
    "\n",
    "            self.generator_losses.append(g_loss)\n",
    "            self.discriminator_losses.append(d_loss)\n",
    "            self.age_losses.append(age_loss)\n",
    "            self.l1_losses.append(l1_loss)\n",
    "            self.ssim_losses.append(ssim_loss)\n",
    "            self.id_losses.append(id_loss)\n",
    "            self.total_losses.append(total_loss)\n",
    "\n",
    "            if d1_logit is None:\n",
    "                self.prefetcher = self._get_train_loader()\n",
    "\n",
    "            if n_iter % self.print_log == 0:\n",
    "                print(f'[{n_iter}/{self.max_iter + 1}]\\tG: {g_loss}\\tD: {d_loss}\\tAge: {age_loss}\\tL1: {l1_loss}\\tSSIMM: {ssim_loss}\\tID: {id_loss}\\tTotal: {total_loss}')\n",
    "            \n",
    "            if n_iter % self.save_iter == 0 or n_iter == self.max_iter:\n",
    "                self._save_model(os.path.join('model', 'pfa-gan', 'checkpoint', f'exp_{self.experiment}'), n_epoch=n_iter, is_checkpoint=True)\n",
    "                self.generate_images(n_iter)\n",
    "        \n",
    "        self._save_model(os.path.join('model', 'pfa-gan'), is_checkpoint=False)\n",
    "\n",
    "    def train(self, inputs, n_iter):\n",
    "        try:\n",
    "            source_img, true_img, source_label, target_label, true_label, true_age, mean_age = inputs\n",
    "            source_img, true_img, source_label, target_label, true_label, true_age, mean_age = source_img.to(device), true_img.to(device), source_label.to(device), target_label.to(device), true_label.to(device), true_age.to(device), mean_age.to(device)\n",
    "        except:\n",
    "            return [None, None, None, None, None, None, None, None, None, None]\n",
    "        \n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        g_source = self.generator(source_img, source_label, target_label)\n",
    "\n",
    "        ###########################\n",
    "        # Train Discriminator\n",
    "        ###########################\n",
    "        self.discriminator_optimizer.zero_grad()\n",
    "\n",
    "        d1_logit = self.discriminator(true_img, true_label)\n",
    "        d3_logit = self.discriminator(g_source.detach(), target_label)\n",
    "\n",
    "        d_loss = 0.5 * (self._ls_gan(d1_logit, 1.) + self._ls_gan(d3_logit, 0.))\n",
    "\n",
    "        with amp.scale_loss(d_loss, self.discriminator_optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "\n",
    "        self.discriminator_optimizer.step()\n",
    "\n",
    "        ###########################\n",
    "        # Train Generator\n",
    "        ###########################\n",
    "        self.optimizer_generator.zero_grad()\n",
    "\n",
    "        ###########################\n",
    "        # GAN Loss\n",
    "        ###########################\n",
    "        gan_logit = self.discriminator(g_source, target_label)\n",
    "        g_loss = self._ls_gan(gan_logit, 1.)\n",
    "\n",
    "        ###########################\n",
    "        # Age Loss\n",
    "        ###########################\n",
    "        age_loss = self._age_criterion(g_source, mean_age)\n",
    "\n",
    "        ###########################\n",
    "        # L1 Loss\n",
    "        ###########################\n",
    "        l1_loss = F.l1_loss(g_source, source_img)\n",
    "\n",
    "        ###########################\n",
    "        # SSIM Loss\n",
    "        ###########################\n",
    "        ssim_loss = self._compute_ssim_loss(g_source, source_img, window_size=10)\n",
    "\n",
    "        ###########################\n",
    "        # ID Loss\n",
    "        ###########################\n",
    "        id_loss = F.mse_loss(\n",
    "            self._extract_vgg_face(g_source),\n",
    "            self._extract_vgg_face(source_img)\n",
    "        )\n",
    "\n",
    "        ###########################\n",
    "        # Pixel-Wise Loss\n",
    "        ###########################\n",
    "        pix_loss_weight = max(\n",
    "            self.pix_loss_weight,\n",
    "            self.pix_loss_weight * (self.decay_pix_factor ** (n_iter // self.decay_pix_n))\n",
    "        )\n",
    "\n",
    "        ###########################\n",
    "        # Total Loss\n",
    "        ###########################\n",
    "        total_loss = \\\n",
    "            g_loss * self.gan_loss_weight + \\\n",
    "            age_loss * self.age_loss_weight + \\\n",
    "            id_loss * self.id_loss_weight + \\\n",
    "            (l1_loss * (1 - self.alpha_fea) + ssim_loss * self.alpha_ssim) * pix_loss_weight\n",
    "        \n",
    "        with amp.scale_loss(total_loss, self.optimizer_generator) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        self.optimizer_generator.step()\n",
    "\n",
    "        return [\n",
    "            d1_logit,\n",
    "            d3_logit,\n",
    "            d_loss,\n",
    "            g_loss,\n",
    "            gan_logit,\n",
    "            age_loss,\n",
    "            l1_loss,\n",
    "            ssim_loss,\n",
    "            id_loss,\n",
    "            total_loss\n",
    "        ]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate_images(self, n_iter, n_source=0, age_group=4):\n",
    "        self.generator.eval()\n",
    "        \n",
    "        real_img = self.test_images[0].to(device)\n",
    "        bs, ch, w, h = real_img.size()\n",
    "        fake_imgs = [real_img, ]\n",
    "\n",
    "        for target in range(n_source + 1, age_group):\n",
    "            output = self.generator(real_img, torch.ones(bs) * n_source, torch.ones(bs) * target)\n",
    "            fake_imgs.append(output)\n",
    "            \n",
    "        fake_imgs = torch.stack(fake_imgs).transpose(1, 0).reshape((-1, ch, w, h))\n",
    "\n",
    "        fake_imgs = fake_imgs * 0.5 + 0.5\n",
    "        grid_img = torchvision.utils.make_grid(fake_imgs.clamp(0., 1.), nrow=age_group - n_source)\n",
    "\n",
    "        self._save_image(\n",
    "            grid_img,\n",
    "            os.path.join(\n",
    "                'test',\n",
    "                'generations',\n",
    "                f'exp_{self.experiment}'\n",
    "            ),\n",
    "            f'{n_iter}_{self.experiment}_test.jpg'\n",
    "        )\n",
    "    \n",
    "    def _save_image(self, grid_img, path, img_name):\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        save_image(\n",
    "            grid_img,\n",
    "            os.path.join(path, img_name),\n",
    "            nrow=1\n",
    "        )\n",
    "\n",
    "    def _ls_gan(self, inputs, targets):\n",
    "        return mean((inputs - targets) ** 2)\n",
    "    \n",
    "    def _age_criterion(self, input, gt_age):\n",
    "        age_logit = self._extract_ages(input)\n",
    "        return F.mse_loss(age_logit, gt_age)\n",
    "        \n",
    "    def _extract_ages(self, x):\n",
    "        x = F.interpolate(x, size=(224, 224), mode='bilinear')\n",
    "        predict_age_pb = self.age_classifier(x)['fc8']\n",
    "        predicted_age = self.__get_predicted_age(predict_age_pb)\n",
    "        return predicted_age\n",
    "\n",
    "    def __get_predicted_age(self, age_pb):\n",
    "        predict_age_pb = F.softmax(age_pb, dim=1)\n",
    "        predict_age = torch.zeros(age_pb.size(0)).type_as(predict_age_pb)\n",
    "        for i in range(age_pb.size(0)):\n",
    "            for j in range(age_pb.size(1)):\n",
    "                predict_age[i] += j * predict_age_pb[i][j]\n",
    "        return predict_age\n",
    "    \n",
    "    def _compute_ssim_loss(self, img1, img2, window_size=11):\n",
    "        channel = img1.size(1)\n",
    "        window = self._create_window(window_size, channel).to(img1.device)\n",
    "\n",
    "        mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "        mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "        return 1.0 - ssim_map.mean()\n",
    "\n",
    "    def _create_window(self, window_size, channel):\n",
    "        _1D_window = self._gaussian(window_size, 1.5).unsqueeze(1)\n",
    "        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "        return window\n",
    "    \n",
    "    def _gaussian(self, window_size, sigma):\n",
    "        gauss = Tensor([math.exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "        return gauss / gauss.sum()\n",
    "    \n",
    "    def _extract_vgg_face(self, inputs):\n",
    "        inputs = self._normalize((F.hardtanh(inputs) * 0.5 + 0.5) * 255,\n",
    "                           [129.1863, 104.7624, 93.5940],\n",
    "                           [1.0, 1.0, 1.0])\n",
    "        return self.vgg_face(inputs)\n",
    "    \n",
    "    def _normalize(self, input, mean, std):\n",
    "        mean = Tensor(mean).to(input.device)\n",
    "        std = Tensor(std).to(input.device)\n",
    "        return input.sub(mean[None, :, None, None]).div(std[None, :, None, None])\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.generator = Generator(self.age_group)\n",
    "        self.generator.apply(self._weights_init)\n",
    "\n",
    "        self.discriminator = Discriminator(\n",
    "            age_group=self.age_group,\n",
    "            repeat_num=int(np.log2(self.image_size) - 4),\n",
    "        )\n",
    "\n",
    "        self.vgg_face = InceptionResnetV1(pretrained='vggface2')\n",
    "        self.vgg_face.cuda()\n",
    "        self.vgg_face.eval()\n",
    "\n",
    "        self.age_classifier = AuxiliaryAgeClassifier()\n",
    "        ckpt = torch.load(\n",
    "            os.path.join(\n",
    "                    'models',\n",
    "                    'pre-trained',\n",
    "                    'dex_age_classifier.pth'\n",
    "                ),\n",
    "            map_location=\"cpu\"\n",
    "        )['state_dict']\n",
    "        ckpt = {k.replace('-', '_'): v for k, v in ckpt.items()}\n",
    "        self.age_classifier.load_state_dict(ckpt)\n",
    "        self.age_classifier.cuda()\n",
    "        self.age_classifier.eval()\n",
    "\n",
    "        self.discriminator_optimizer = Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            self.init_lr,\n",
    "            betas=(0.5, 0.99)\n",
    "        )\n",
    "\n",
    "        self.optimizer_generator = Adam(\n",
    "            self.generator.parameters(),\n",
    "            self.init_lr,\n",
    "            betas=(0.5, 0.99)\n",
    "        )\n",
    "\n",
    "        if self.restore_iter > 0:\n",
    "            self._load_model(\n",
    "                os.path.join(\n",
    "                    'model',\n",
    "                    'pfa-gan',\n",
    "                    'checkpoint',\n",
    "                    f'exp_{self.experiment}'\n",
    "                ),\n",
    "                self.restore_iter,\n",
    "                is_checkpoint=True\n",
    "            )\n",
    "\n",
    "        self.generator, self.optimizer_generator = self._to_ddp(self.generator, self.optimizer_generator)\n",
    "        self.discriminator, self.discriminator_optimizer = self._to_ddp(self.discriminator, self.discriminator_optimizer)\n",
    "        self.vgg_face = self._to_ddp(self.vgg_face)\n",
    "        self.age_classifier = self._to_ddp(self.age_classifier)\n",
    "    \n",
    "    def _to_ddp(self, modules: Union[list, nn.Module], optimizer: torch.optim.Optimizer = None, opt_level: int = 0) -> Union[DistributedDataParallel, tuple]:\n",
    "        if isinstance(modules, list):\n",
    "            modules = [x.cuda() for x in modules]\n",
    "        else:\n",
    "            modules = modules.cuda()\n",
    "\n",
    "        if optimizer is not None:\n",
    "            modules, optimizer = amp.initialize(\n",
    "                modules,\n",
    "                optimizer,\n",
    "                opt_level=\"O{}\".format(opt_level), verbosity=1\n",
    "            )\n",
    "            \n",
    "        if optimizer is not None:\n",
    "            return modules, optimizer\n",
    "        else:\n",
    "            return modules\n",
    "\n",
    "    def _get_train_loader(self):\n",
    "        train_dataset = CACD_Dataset(\n",
    "            'data',\n",
    "            'cacd',\n",
    "            age_group=self.age_group\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        return DataPrefetcher(train_loader, [0, 1])\n",
    "\n",
    "    def _get_test_images(self):\n",
    "        test_dataset = CACD_Dataset(\n",
    "            'data',\n",
    "            'cacd'\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            dataset=test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        return next(iter(test_loader))\n",
    "\n",
    "    def _weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            if hasattr(m.bias, 'data'):\n",
    "                m.bias.data.fill_(0)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            m.bias.data.zero_()\n",
    "    \n",
    "    def _save_model(self, path, n_epoch=0, is_checkpoint=False):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        path = os.path.join(path, 'pfa-gan.obj') if not is_checkpoint else os.path.join(path, f'pfa-gan_{n_epoch}.obj')\n",
    "\n",
    "        torch.save({\n",
    "            'discriminator_state_dict': self.discriminator.state_dict(),\n",
    "            'discriminator_optimizer_state_dict': self.discriminator_optimizer.state_dict(),\n",
    "            'generator_state_dict': self.generator.state_dict(),\n",
    "            'generator_optimizer_state_dict': self.optimizer_generator.state_dict()\n",
    "        }, path)\n",
    "    \n",
    "    def _load_model(self, path, n_epoch=0, is_checkpoint=True):\n",
    "        path = os.path.join(path, 'pfa-gan.obj') if not is_checkpoint else os.path.join(path, f'pfa-gan_{n_epoch}.obj')\n",
    "\n",
    "        checkpoint = torch.load(path)\n",
    "\n",
    "        self.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "        self.discriminator_optimizer.load_state_dict(checkpoint['discriminator_optimizer_state_dict'])\n",
    "        self.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        self.optimizer_generator.load_state_dict(checkpoint['generator_optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfa_gan = PFA_GAN(\n",
    "    alpha_fea=0.025,\n",
    "    alpha_ssim=0.15,\n",
    "    gan_loss_weight=100,\n",
    "    id_loss_weight=0.02,\n",
    "    age_loss_weight=0.4,\n",
    "    pix_loss_weight=0.,\n",
    "    decay_pix_factor=0.7,\n",
    "    decay_pix_n=15,\n",
    "    batch_size=8,\n",
    "    save_iter=5000,\n",
    "    restore_iter=40000,\n",
    "    num_workers=4,\n",
    "    experiment=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfa_gan.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
